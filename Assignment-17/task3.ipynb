{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10876214",
        "outputId": "a60557fa-b958-4048-cadf-c0d174bbff0a"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/iot_sensor.csv')\n",
        "print(\"DataFrame loaded successfully. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame loaded successfully. Displaying the first 5 rows:\n",
            "             timestamp sensor_id  temperature  humidity\n",
            "0  2025-02-01 00:00:00        S2         24.0      40.0\n",
            "1  2025-02-01 01:00:00        S3         30.0       NaN\n",
            "2  2025-02-01 02:00:00        S1         24.0      50.0\n",
            "3  2025-02-01 03:00:00        S2         24.0       NaN\n",
            "4  2025-02-01 04:00:00        S3         23.0      42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6a28cdd"
      },
      "source": [
        "## Handle Missing Values\n",
        "\n",
        "### Subtask:\n",
        "Apply forward fill (fill) to handle any missing values in the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bddd3ca"
      },
      "source": [
        "**Reasoning**:\n",
        "I will apply forward fill to handle missing values in the DataFrame and then display the first few rows to verify the changes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7398823",
        "outputId": "c8f8d610-8109-49d5-fd4e-5041b4df71e0"
      },
      "source": [
        "df.ffill(inplace=True)\n",
        "print(\"DataFrame after forward fill. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after forward fill. Displaying the first 5 rows:\n",
            "             timestamp sensor_id  temperature  humidity\n",
            "0  2025-02-01 00:00:00        S2         24.0      40.0\n",
            "1  2025-02-01 01:00:00        S3         30.0      40.0\n",
            "2  2025-02-01 02:00:00        S1         24.0      50.0\n",
            "3  2025-02-01 03:00:00        S2         24.0      50.0\n",
            "4  2025-02-01 04:00:00        S3         23.0      42.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5de24a24"
      },
      "source": [
        "## Remove Sensor Drift\n",
        "\n",
        "### Subtask:\n",
        "Calculate a rolling mean (e.g., with a window of 5 or 10, to be determined upon code generation) for relevant sensor reading columns to remove drift. Subtract this rolling mean from the original readings.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb3ada45"
      },
      "source": [
        "**Reasoning**:\n",
        "To remove sensor drift, I will calculate a rolling mean for both 'temperature' and 'humidity' columns with a window size of 10 and then subtract these rolling means from their respective original columns. Finally, I will display the first 5 rows of the modified DataFrame.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8566962b",
        "outputId": "02e77945-a177-436f-b7b2-1936e922760c"
      },
      "source": [
        "window_size = 10\n",
        "\n",
        "df['temperature_rolling_mean'] = df['temperature'].rolling(window=window_size, min_periods=1).mean()\n",
        "df['temperature'] = df['temperature'] - df['temperature_rolling_mean']\n",
        "\n",
        "df['humidity_rolling_mean'] = df['humidity'].rolling(window=window_size, min_periods=1).mean()\n",
        "df['humidity'] = df['humidity'] - df['humidity_rolling_mean']\n",
        "\n",
        "df.drop(columns=['temperature_rolling_mean', 'humidity_rolling_mean'], inplace=True)\n",
        "\n",
        "print(f\"DataFrame after removing sensor drift with a rolling mean window of {window_size}. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after removing sensor drift with a rolling mean window of 10. Displaying the first 5 rows:\n",
            "             timestamp sensor_id  temperature  humidity\n",
            "0  2025-02-01 00:00:00        S2          0.0  0.000000\n",
            "1  2025-02-01 01:00:00        S3          3.0  0.000000\n",
            "2  2025-02-01 02:00:00        S1         -2.0  6.666667\n",
            "3  2025-02-01 03:00:00        S2         -1.5  5.000000\n",
            "4  2025-02-01 04:00:00        S3         -2.0 -2.400000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "219be21f"
      },
      "source": [
        "## Normalize Numerical Sensor Readings\n",
        "\n",
        "### Subtask:\n",
        "Normalize the numerical sensor readings ('temperature', 'humidity') using standard scaling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c8c3398"
      },
      "source": [
        "**Reasoning**:\n",
        "I need to normalize the numerical sensor readings ('temperature', 'humidity') using standard scaling. This requires importing StandardScaler from sklearn.preprocessing, fitting it to the relevant columns, and then transforming the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19d0ba1a",
        "outputId": "fe7c308f-3412-4fde-dc2f-bef588887d70"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df[['temperature', 'humidity']] = scaler.fit_transform(df[['temperature', 'humidity']])\n",
        "\n",
        "print(\"DataFrame after standard scaling numerical features. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after standard scaling numerical features. Displaying the first 5 rows:\n",
            "             timestamp sensor_id  temperature  humidity\n",
            "0  2025-02-01 00:00:00        S2     0.018389 -0.011347\n",
            "1  2025-02-01 01:00:00        S3     1.176150 -0.011347\n",
            "2  2025-02-01 02:00:00        S1    -0.753451  1.762878\n",
            "3  2025-02-01 03:00:00        S2    -0.560491  1.319322\n",
            "4  2025-02-01 04:00:00        S3    -0.753451 -0.650067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2dcf0c45"
      },
      "source": [
        "## Encode Categorical Sensor IDs\n",
        "\n",
        "### Subtask:\n",
        "Encode categorical sensor IDs using an appropriate method (e.g., One-Hot Encoding or Label Encoding)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9c6d980c"
      },
      "source": [
        "**Reasoning**:\n",
        "To encode the categorical 'sensor_id' column, One-Hot Encoding is a suitable method as it avoids implying any ordinal relationship between the sensor IDs. I will use `pd.get_dummies` for this purpose and then display the head of the DataFrame to show the new encoded columns.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a93fc756",
        "outputId": "b4c04101-03e3-4e6e-fbb6-5fa048bd3821"
      },
      "source": [
        "df = pd.get_dummies(df, columns=['sensor_id'], prefix='sensor')\n",
        "\n",
        "print(\"DataFrame after One-Hot Encoding sensor_id. Displaying the first 5 rows:\")\n",
        "print(df.head())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after One-Hot Encoding sensor_id. Displaying the first 5 rows:\n",
            "             timestamp  temperature  humidity  sensor_S1  sensor_S2  sensor_S3\n",
            "0  2025-02-01 00:00:00     0.018389 -0.011347      False       True      False\n",
            "1  2025-02-01 01:00:00     1.176150 -0.011347      False      False       True\n",
            "2  2025-02-01 02:00:00    -0.753451  1.762878       True      False      False\n",
            "3  2025-02-01 03:00:00    -0.560491  1.319322      False       True      False\n",
            "4  2025-02-01 04:00:00    -0.753451 -0.650067      False      False       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54c1d0f9"
      },
      "source": [
        "## Summarize Processed Data\n",
        "\n",
        "### Subtask:\n",
        "Summarize the shape and first few rows of the processed dataset, confirming its readiness for anomaly detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a6f144e"
      },
      "source": [
        "**Reasoning**:\n",
        "To confirm the dataset's readiness for anomaly detection, I will display the shape of the DataFrame and its first 5 rows to provide a summary of the processed data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30b4d59",
        "outputId": "bd9864c5-0148-4f3d-9cdd-760c0923254d"
      },
      "source": [
        "print(\"Shape of the processed DataFrame:\", df.shape)\n",
        "print(\"\\nFirst 5 rows of the processed DataFrame:\")\n",
        "print(df.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the processed DataFrame: (50, 6)\n",
            "\n",
            "First 5 rows of the processed DataFrame:\n",
            "             timestamp  temperature  humidity  sensor_S1  sensor_S2  sensor_S3\n",
            "0  2025-02-01 00:00:00     0.018389 -0.011347      False       True      False\n",
            "1  2025-02-01 01:00:00     1.176150 -0.011347      False      False       True\n",
            "2  2025-02-01 02:00:00    -0.753451  1.762878       True      False      False\n",
            "3  2025-02-01 03:00:00    -0.560491  1.319322      False       True      False\n",
            "4  2025-02-01 04:00:00    -0.753451 -0.650067      False      False       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe884677"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   The `iot_sensor.csv` dataset was successfully loaded into a pandas DataFrame.\n",
        "*   Missing values in the dataset were handled by applying a forward fill strategy.\n",
        "*   Sensor drift was removed from 'temperature' and 'humidity' readings by subtracting a rolling mean with a window size of 10.\n",
        "*   The numerical 'temperature' and 'humidity' features were normalized using `StandardScaler`.\n",
        "*   The categorical 'sensor_id' column was successfully One-Hot Encoded, creating new binary columns like 'sensor\\_S1', 'sensor\\_S2', 'sensor\\_S3'.\n",
        "*   The final processed DataFrame has a shape of (50, 6), indicating 50 rows and 6 columns, comprising the timestamp, two normalized sensor readings, and three one-hot encoded sensor ID columns.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   The dataset is now fully preprocessed and ready for an anomaly detection algorithm to be applied.\n",
        "*   The next step would involve selecting and implementing an anomaly detection model, such as Isolation Forest or One-Class SVM, to identify unusual patterns in the processed sensor data.\n"
      ]
    }
  ]
}